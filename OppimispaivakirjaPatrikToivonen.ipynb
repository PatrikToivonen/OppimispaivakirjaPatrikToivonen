{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e83544f",
   "metadata": {},
   "source": [
    "# Oppimispäiväkirja Patrik Toivonen\n",
    "## Ensimmäinen viikko, Mitä on datatiede?\n",
    "Ensimmäisellä viikolla osallistuin aloitusluennolle ja olin kurssin aiheesta suhteellisen kiinnostunut ja ylipäätään kurssin suorittaminen vaikutti mielenkiintoiselta. Olen koko kurssin ajan Turussa, joten luennoille osallistuminen tarkoittaa kaikkien luentojen kohdalla lähtökohtaisesti luennon katsomista livenä Panopton kautta tai vaihtoehtoisesti myöhemmin tallenteen katsomista. Lähtökohtaisesti pidin itseäni melko huonona koodamisen suhteen ja itseäni hieman kauhistuttikin ajatus oppimispäiväkirjan toteuttamisesta Jupyter notebookkina sekä siihen vaadittavia viikottaisia koodiosioita. Myös viimeiseksi mainittu hieman mietityttää itseäni, sillä koodaaminen ei ole oma vahvuusalueeni. En ollut koskaan ennen käyttänyt Jupyteria, joten nähtäväksi jää miten päiväkirjan toteuttaminen tällä menetelmällä tulee onnistumaan. Oppimispäiväkirjaa näin hieman jälkikäteen kirjoittaessani oman jaksamiseni ja muiden tehtävien aiheuttaneen aloittamisen lykkääntymisen, huomaan olevani hieman kurssin toteutustavasta sekä tehtävistä ulkona. Tästä johtuen itseltäni jäivät myös koodiklinikoiden hyödyntämiset hyvin vähäisiksi, mikä jälkikäteen ajateltuna olisi ollut itselleni varmasti hyvin suotavaa. Osan koodiklinikoista katselin jälkikäteen harjoitustyön tekemisen sekä tämän päiväkirjan toteuttamisten helpottamiseksi. Kurssin keskeisimmät tavoitteet itselleni ovat datatieteen parempi ymmärrys, hyödyntämiskohteiden selkeämpi ymmärtäminen sekä varsinaisen datankäsittelyn parantaminen itseni kohdalla. Kuitenkin huomaan jo ennen kurssia oman jaksamiseni olevan hieman loppu, joten tähtään kurssilla erityisesti läpipääsyyn sekä omaan oppimiseeni, kuin korkeisiin arvosanoihin. \n",
    "\n",
    "Ensimmäisen luennon aiheena olivat kurssin suorittamiseen liittyvät tekijät, jotka käytiin ensimmäiseksi läpi, kuten lähes kaikilla kursseilla on ollut tapana. Suorituksessa käytiin läpi ensinnäkin tämän oppimispäiväkirjan toteuttaminen sekä myöhemmin toteutettava harjoitustyö, joka on myös oleellinen osa kurssin suorittamista. Tästä siirryttiin varsinaiseen aiheeseen, joka ensimmäisellä luennolla oli määrittely siitä, mitä datatiede on, millaisia edellytyksiä datatieteelle voidaan asettaa sekä millaisia työvälineitä datatieteessä voidaan yleisesti hyödyntää. Itselleni tuli myös uutena asiana datatieteen jakaminen karkeasti neljään kokonaisuuteen liiketoimintaosaaminen, ohjelmointi- ja tietokantaosaaminen, tilastollinen analyysi sekä datalähtöinen viestintä ja visualisointi.\n",
    "\n",
    "Itselläni oli ennen kurssin alkua vain hyvin pintapuoleista tietoa siitä, mitä kaikkea voidaan pitää datatieteenä. Itselläni on alla dataan liittyviä kursseja lähinnä vain Basics for Business data analytics, jossa mielestäni varsinaiseen datatieteeseen ei keskitytty kovin perusteellisesti. Datatiede esiteltiin luennolla esimerkiksi tietotekniikan, matematiikan sekä liiketoiminnan osaamisten yhdistämisenä ja miten sitä voidaan hyödyntää monenlaisten alojen liiketoiminnan tehostamisena. Datatieteen avulla voidaan luoda dataa hyödyntämällä malleja, jota voidaan taas hyödyntää niin tekoälyn toiminnan kuin analytiikan apuna. Datasta mainittiin sen määrän olevan suurempi kuin koskaan ennen ja määrän vain kasvavan tulevaisuudessa. Seuraavana aiheena olivat analyysiympäristö sekä datan käsittelyyn käyettävät työvälineet, kuten tilastolaskentaympäristö R, sekä sen toimintaa osittain korvaamaan sekä lisäämään useat Python pohjaiset ympäristöt. Tässä vaiheessa luentoa esiteltiin myös lisää työkirjapohjaisia laskentaympäristöjä, kuten CSC sekä JupyterLab, jonka osana myös Jupyter notebooks on, jolla tämäkin oppimispäiväkirja on toteutettu. \n",
    "\n",
    "Viikon tärkeimpinä oppeina itselleni olivat ymmärrys datan aina vain kasvavasta määrästä, sekä miten suurta hyötyä etenkin tulevaisuudessa tämän datamäärän seasta oleellisen tiedon hankinnalla voi olla liiketoiminnan kannalta. Lisäksi itselleni tuli uutena asiana Python-pohjaiset työkirjapohjaiset ympäristöt, kuten Jupyter ja mielestäni on hyvin mielenkiintoista päästä opettelemaan näiden työkalujen tehokkaampaa käyttöä. \n",
    "Itselläni ei ole ainakaan vielä tässä vaiheessa kehitysehdotuksia kurssin kehittämiseen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015629ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demokoodi viikon aiheista, itselleni oppeja olivat pandas kirjaston käyttäminen sekä lähes kaikki\n",
    "#mitä Jupyteri notebookin avulla toteutettavassa analyysissä voidaan käyttää\n",
    "#lisäksi datasetin lukeminen \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "URL= 'http://....'\n",
    "muuttuja_data =pd.read_csv(URL, compression= 'gzip')\n",
    "#tätä käytettiin toisessa harjoitustyön vaiheessa datan lukemiseen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eda3d2",
   "metadata": {},
   "source": [
    "## Toinen viikko, Datatieteen prosessi\n",
    "Toisella luentoviikolla keskityttiin datatieteen prosesseihin, tarkasteltiin millaisia datalähteitä on olemassa ja miten datan kerääminen toteutetaan käytännössä. Itse en osallistunut livenä luennolle vaan katsoin sen jälkikäteen tallenteena. Tämän viikon oppimispäiväkirjan kirjoittamisen pohjana käytän luennolla käytettyä Jupyter notebook materiaalia sekä luentotallennetta. \n",
    "\n",
    "Luennon oppimistavoittena olivat juuri edelläkin mainitut asiat datalähteistä, keräämisestä käytännössä sekä lisäksi mitä datan keräämisessä tulee ottaa huomioon. Liikkeelle lähdettiin datatieteen prosessista, jota esiteltiin käsitekarttamaisen mallin avulla. Mallin tarkoituksena oli selkeättää mitä osia datatieteen prosessiin kuuluu, miten nämä eri tehtävät voidaan liittää toisiinsa sekä miten eri tehtävät seuraavat toisiaan. Kiteytettynä itselleni jäi mieleen miten datan keräämisen jälkeen data puhdistetaan ja muokataan käytön kannalta sopivaan muotoon. Nämä ovat molemmat osa valmistelu-vaihetta varsinaiselle datatieteelle. Seuraavaksi puhutaan analyysivaiheesta, jossa muodostetaan erilaisia analyysimalleja, jotka pyritään toteuttamaan, näiden tuloksia tarkastellaan ja mahdolliset virheet analyysin koodeissa korjataan. Tämä kohta toteutetaan niin moneen kertaan, että tuloksiin ja niiden laatuun ollaan tyytyväisiä. Tästä siirrytään datatieteen seuraavaan vaiheeseen tulosten reflektoinnista, jossa saatuja tuloksia pyritään vertailemaan aiempaan dataan tai tuloksiin ja saaduista tuloksista tehdään dokumentaatiota. Analyysien tuloksista voidaan myös järjestää kokouksia tuloksista keskustelemiseen. Tästä jatketaan mahdollisten vaihtoehtoisten toteutustapojen tutkimiseen, mikäli analyysiin olisi mahdollista löytää vieläkin tehokkaampia menetelmiä. Datatieteilijästä todettiin mallin jatkoksi, miten tärkeää on ymmärtää datan tuottama arvo liiketoiminnan kannalta. Lisäksi tarvitaan tietenkin prosessiymmärrystä, mutta tässä datan avulla tapahtuva arvonluonti nostetaan korkeimmalle jalustalle. \n",
    "\n",
    "Seuraavaksi aiheessa siirryttiin liiketoimintarelevanssiin, jossa tarkasteltiin miten voidaan perustella juuri data-analytiikan tuoma liiketoimintarelevanssi. Tässä lähdettiin liikkeellee siitä, että todettiin miten on osoitettu data-analytiikan kyvykkyyksien avulla voidaan kasvattaa yrityksen suorituskykyä. Tämä perustui luentomateriaalin mukaan siihen miten analytiikan avulla on mahdollista lisätä ymmärrystä liiketoiminnan prosesseista. Tätä ymmärryksen kasvua pyrittiin selkeyttämään esitellemällä analytiikan nelikenttä, jossa kuvailtiin eri analytiikan muotoja. Pääpointtina itselleni näistä jäi mieleen lähinnä erilaisten analytiikkamuotojen pyrkivän selittämään miten tapahtuu, miksi tapahtuu, mitä todennäköisesti tapahtuu sekä mitä pitäisi tapahtua. Lisäksi annettiin esimerkki ennakoivasta analytiikasta eli 'mitä pitäisi tapahtua'-kohdasta. Seuraavana aiheena oli tarkastelu analytiikan nykytilasta yrityksistä, eli miten laajasti analytiikkaa pyritään keskimäärin hyödyntämään yrityksen toiminnan kehittämisessä. Tästä aiheesta nostoina toisin itse esille suhteellisen matalan osan yrityksistä, joilla on erillinen data-analytiikkatiimi, sillä sellainen löytyi luennon materiaalin mukaisesti vain noin 36% yrityksiä, jotka ottivat osaa materiaalissa mainittuun kyselyyn. Lisäksi nykyaikaisia analytiikkatyökaluja käytti niin ikään vain 38% kyselyn yrityksistä, mikä omasta mielestäni voi olla kytköksissä edelliseen data-analytiikkatiimin hyödyntämiseen. Mielenkiintoisena näin itse nämä matalat luvut kun seuraavaksi mainittiin suuren osan yrityksistä kuitenkin tiedostavan, miten analytiikka tulee vaikuttamaan yrityksen teollisuuden alaan seuraavan kolmen vuoden sisällä. Tämä oli mielestäni hyvin ristiriitaisen kuuloista, sillä jos vaikutus tiedostetaan oli itsestäni hyvin kummallista, että kuitenkin näinkin pieni osa ottaa analytiikan hyödyntämisen oikeasti tosissaan. \n",
    "\n",
    "Seuraava isompi luennon aihe oli 'raapijoiden' ja 'ryömijöiden' käyttö. Näillä tarkoitettiin ryömijän kohdalla robottia, joka käy systemaattisesti läpi verkko-osoitteita ja tämän tarkoituksena on sivujen indeksointi. Itselleni ryömijän toiminta jäi kuitenkin luennosta sekä materiaalista huolimatta hieman epäselväksi. Toisena mainittuna oli raapija, joka puolestaan kerää tietoa verkkosivuilta tunnistamalla yleisimmin metaelementtejä sivun rakenteesta ja näiden avulla tallentamalla mielenkiintoista tietoa. Ymmärsin, että näitä menetelmiä usein hyödynnetään yhdessä, jolloin ryömijä asettaa sivuja jonoon, joita raapija puolestaan käy läpi tallentaen mielenkiintoista dataa. \n",
    "Luennolla tarkasteltiin näiden lisäksi myös erilaisia datan muotoja, jotka jaoteltiin Pythonin standardisen hierarkian mukaisesti. Itselläni on hyvin vähän aiempaa kokemusta Pythonista ja yleisesti koodaamisesta, joten ymmärsin lähinnä miten erilaiset datan muodot on jaoteltu erilaisiksi tietorakenteiksi, joilla on erilaisia hierarkisia tasoja, mutta tähän oma ymmärrykseni suurinpiirtein jäikin. \n",
    "\n",
    "Mielestäni tärkeimmät opit luennolta ja viikolta olivat ymmärrys datan hyödyntämisen merkityksestä liitoiminnan suorituskyvyn kasvattamisessa, ymmärrys erilaisista analyytikan toimista, jotka kuvastavat erilaisia asioita, joihin analyytikan menetelmien avulla pyritään vastaamaan. Lisäksi luennolla mainittu datan jalostaminen on mielestäni yksi tärkeistä tämän luentoviikon opeista. Tämä lähinnä oman kokemukseni harjoitustyötä toteuttaessa, jossa huomasin, miten datan siivoamisen sekä jalostamisen heiko taso voi heijastua itse datan analytiikkaan ja hyödyntämis mahdollisuuksiin. Viimeisenä huomiona opituista asioista tulevaisuudessa kasvavan datan määrän mukana tuoma analytiikan tarpeen kasvu, johon yritysten tulisi mielestäni panostaa enemmän jo nykyisellään, sillä toimintatapojen muuttaminen ei tapahdu hetkessä. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demokoodia toisen viikon asioista, ryömijät ja raapijat: Lähde koodiklinikka 2: https://github.com/InfoTUNI/joda2021/blob/master/koodiesimerkit/Session%202%20-%20Crawlers%20and%20Scrapers.ipynb\n",
    "import scrapy\n",
    "#tarkasteltiin Amazonin tuotearvioita ja näihin ryömijöiden sekä raapijoiden soveltamista\n",
    "class AmazonScraperSpider(scrapy.Spider):\n",
    "    name='amazon_scraper'\n",
    "    allowed_domains['amazon.com']\n",
    "start_urls=#tähän haluttu amazon url osoite, jonka tuotteen arvosteluja halutaan tarkastella\n",
    "\n",
    "#Varsinaine raapijan kutsunta toteutettiin koodiklinikalla itselleni täysin uudella tavalla\n",
    "!scrapy runspider amazon_scraper.py -o out.json\n",
    "#tästä saatiin pitkä lista dataan tehdyistä arvosteluista halutulla URL-sivulla\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6674c0",
   "metadata": {},
   "source": [
    "## Kolmas viikko, Koneoppimisen periaatteet\n",
    "Kolmannella viikolla käsittelyssä oli koneoppiminen ja miten se liittyy osaksi datatiedettä. Tarkasteltiin myös mitä asioista liittyy koneoppimisen sekä miten koneoppimista voidaan soveltaa datatieteessä. Itse osallistuin liveluennolle Panopton kautta, mutta en ollut fyysisesti luennolla paikalla. Materiaalina toimii siis luennon tallenne sekä luennolla käytetty Jupyter työkirja. Itselläni ei juurikaan ole käytännönkokemusta koneoppimisen sovelluksista tekniikan alalla, joten luennon aihe itsellään oli mielestäni mielenkiintoinen.\n",
    "\n",
    "Asiaa lähdettiin tarkastelemaan määrittelemällä koneoppimisen eri tyyppejä luennolla esitellyn kaaviomallin avulla. Itselleni kaaviosta jäivät lähinnä mieleen koneoppimisen jakamisen eri kategorioihin oppimisen valvonnan perusteella. Näistä jaon tasoilta koneoppimista jaoteltiin oppimisen muodon perusteella. Mielestäni koneoppiminen on konseptina hyvin mielenkiintoinen sen suuren hyödyntämisen kasvun myötä tulevaisuudessa. En ollut ajatellut esimerkiksi itse ajavien autojen toiminnan perustuvan nimenomaan koneoppimiseen, mikä oli mielestäni luennon tarkastelun jälkeen lähes itsestään selvää. Oli helppoa luennon jälkeen ymmärtää miten auton itseohjaaminen perustuu koneoppimiseen liikennemerkkien tunnistamisen sekä aiemman kerätyn datan ja aktiivisten sensorien yhteistoimintaan. Koneoppimisen määrittelystä siirryttiin tekoälyyn, josta lähinnä mainittiin miten se ei itsessään ole liiketoimintaa pelastava kaikkivoipa menetelmä, vaan ennemminkin työkalu, jolla voidaan tehostaa liiketoimintaa, mikäli perustoiminnassa kaikki on yleisesti kunnossa. Seuraava luennon aihe oli ohjattu oppiminen, jolla tarkoitettiin luennon esimerkissä lähinnä toimintatapaa, jossa ihmisten osaamista sekä asiantuntemusta hyödyntämällä pyrittiin muokkaamaan lähtödataa muotoon, josta koneoppimisen olisi sitä mahdollista paremmalla menestyksellä hyödyntää. Tälläisiä asioita voisiva esimerkiksi olla datan siivoamista, uusien muuttujien lisäämistä toiminnan sujuvoittamiseksi tai muita vastaavia menetelmiä, jotka helpottavat parempien ja luotettavampien tulosten saamista koneoppimista hyödynnettäessä.Luennon esimerkkinä oli Amazon asiakaspalaute data, josta muokkaamalla, siivoamalla sekä tämän jälkeen koneoppimista hyödyntämällä kerättiin avainsanoja sekä arvioiden asioita kyettiin kiteyttämään. Tämä puolestaan vähentää suuresti tallennettavan tiedon määrää verrattuna, että tallennettaisiin avainsanojen ja lyhyiden listojen sijasta kokonaisia arviointikirjoituksia. \n",
    "\n",
    "Luennon seuraavana asiana oli ensimmäinen analyysiesimerkki jossa tutkittiin käytännön työväline, joka kykeni materiaalin mukaan tekemään itsenäisesti liiketoimintarelevantteja päätöksiä. Esimerkissä tarkasteltiin lainan hakemisen prosessia, jonka päätöksiä tarkasteltava tekoäly teki. Itselleni esimerkin seuraaminen oli lähinnä koodirivien tarkastelua, mutta koska itselläni on yhä kovin vähän koodaustaustaa, en mielestäni saanut kovin paljoa irti itse koodin tarkastelusta. Ymmärsin, että dataa siivottiin, se jaettiin pienemmiksi aineistoiksi joita hyädynnettiin ennusteiden laskemisessa ja lopuksi tarkasteltiin vielä millaisia keskiarvoisia virheitä analyysissä voitaisiin olettaa. \n",
    "\n",
    "Viikon luento oli itselleni tähän mennessä samalla mielenkiintoisin, mutta suhteellisen suuren koodimääränsä vuoksi myös haastavinta saada kunnollista ymmärrystä siitä, mitä kaikkea aiheessa todellisuudessa toteutettiin. Tärkeitä oppeja mielestäni viikolta olivat ymmärrys koneoppimisen hyödyntämisen kasvusta sekä sen hyödyntämisen mahdollisuudet erilaisissa konteksteissa. Lisäksi mielestäni oli tärkeää ymmärtää myös, miten koneoppimisen käytön lisääntymisen myötä on myös tärkeää ymmärtää miten liiketoiminnan saavuttaman hyödyn maksimoimiseksi koneoppimisen avulla vaatii kuitenkin perusasioiden olevan suhteellisen hyvällä mallilla. Koneoppiminen tai tekoäly ei ole käänteentekevä asia, mikäli liiketoimintamalli ei muuten ole kokonaisuutena hallinnassa. Näillä metodeilla voidaan luoda lisäarvoa, niiden perustellulla implementoinnilla, mutta pelkkä niiden käyttäminen ei pelasta muuten huonolla pohjalla olevaa liiketoimintaa. Lisäksi, vaikka mainitsinkin ettei itselläni ole koodikokemusta, oli yhtenä oppina ainakin itselleni datan käsittelyn seuraaminen koodinpohjalta, etenkin luentomateriaaleja jälkikäteen tarkastellessa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d255c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kolmannen viikon asioden demokoodia:\n",
    "#Demona toimii koneoppimisen kannalta harjoitustyössäni toteuttama lineaarinen regressio, joka oli itselleni uusi asia Pythonilla \n",
    "#toteutettuna\n",
    "lr = linear_model.LinearRegression()\n",
    "x = df2['review_scores_location'].values[:, np.newaxis]\n",
    "y = df2['reviews_per_month']\n",
    "classifier = lr.fit(x,y)\n",
    "plt.scatter(x,y, color = 'red')\n",
    "plt.plot(x,classifier.predict(x), color = 'black')\n",
    "plt.xlabel('Arvostelujen sijainti')\n",
    "plt.ylabel('Arvostelujen määrä/kk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2394a1",
   "metadata": {},
   "source": [
    "## Neljäs viikko, Harjoitustyön esittely\n",
    "Neljännellä viikolla keskityttiin harjoitustyön toteuttamisen aloittamiseen ja mitä harjoitustyöhön kuuluu. Lisäksi tarkasteltiin mitä varsinaiseen datatieteen prosessiin sekä sen käytäntöihin sisältyy. En ollut kyseisellä luennolla itse läsnä vaan katsoin sen jälkikäteen Panoptosta tallenteena, joten en voinut osallistua luennolla järjestettyihin ryhmäharjoituksiin. Materiaalina toimii luennon tallenne sekä luennon Jupyter työkirja. Luennolla esiteltiin CRISP-DM-malli, joka oli ymmärtämäni mukaan lähinnä erilaisten datatieteen sovellusten, tässä tapauksessa toteutettavan harjoitustyön, jäsentämistä sekä ajattelua helpottava toteuttamistyökalu. Tässä vielä painotettiin miten todellisuudessa dataprojekteissa on lähtökohtana ensisijaisesti liiketoimintaongelma tai vastaava eikä itse data. Tämän jälkeen esiteltiin luennon materiaalissa Mahdollisuuskehikon käyttöä, josta siirryttiin ryhmäkeskustelujen, joihin en valitettavasti voinut osallistua, kautta itse toteutettavaan harjoitustyöhön ja mitä siihen tulee sisältymään. Harjoitustyön vaiheina olivat datan kerääminen, datan käsitteleminen, datan rikastaminen sekä datan visualisointi. Lisäksi harjoitustyön totetuksessa käsiteltiin koneoppimista omana osanaan sekä viimeisenä kokonaisuuden toteutusta avattiin omana kohtanaan. Avaan tässä luvussa myös oman harjoitustyöni toteuttamisen.\n",
    "\n",
    "Omalla kohdallani päätin valita datakseni valmiin datasetin ehdotetulta AirBnB:n sivulta, josta päädyinkin Austin, Texasin dataan. Aloitin harjoitustyön toteutuksen hieman myöhään, sillä itselläni oli jo lähellä kurssin keskeyttäminen jaksamiseni takia, mutta päätin kuitenkin, että haluan saada tämän suoritettua. Tavoitteeni olikin siis oman osaamiseni puitteissa tehdä parhaani, mutta tiedostin, että toteutukseni rajoittuisi lähinnä yksinkertaisempiin toteutusvaihtoehtoihin harjoitustyön osalta. Datan valitsemisen sekä toteustavan avaamisen jälkeen muodostin datasta dataframen ja tarkastelin minkälaista dataa olin tullut valinneeksi. Alla toteuttamani kirjastojen importaaminen sekä datan alkukäsittely, jonka toteutin harjoitustyössäni. Sain suuresti apua tarkastelemalla erilaisia menetelmiä, joita oli käytetty aiemmilla kurssin toteutuskertojen harjoitustöissä."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b46f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                            listing_url       scrape_id  \\\n",
      "0          1078      https://www.airbnb.com/rooms/1078  20211211051409   \n",
      "1          2265      https://www.airbnb.com/rooms/2265  20211211051409   \n",
      "2          5245      https://www.airbnb.com/rooms/5245  20211211051409   \n",
      "3          5456      https://www.airbnb.com/rooms/5456  20211211051409   \n",
      "4          5769      https://www.airbnb.com/rooms/5769  20211211051409   \n",
      "...         ...                                    ...             ...   \n",
      "11369  53760016  https://www.airbnb.com/rooms/53760016  20211211051409   \n",
      "11370  53764066  https://www.airbnb.com/rooms/53764066  20211211051409   \n",
      "11371  53767190  https://www.airbnb.com/rooms/53767190  20211211051409   \n",
      "11372  53769566  https://www.airbnb.com/rooms/53769566  20211211051409   \n",
      "11373  53770692  https://www.airbnb.com/rooms/53770692  20211211051409   \n",
      "\n",
      "      last_scraped                                               name  \\\n",
      "0       2021-12-11                  *UT/Hyde Park Craftsman Apartment   \n",
      "1       2021-12-11   Zen-East in the Heart of Austin (monthly rental)   \n",
      "2       2021-12-11  Eco friendly, Colorful, Clean, Cozy monthly share   \n",
      "3       2021-12-11          Walk to 6th, Rainey St and Convention Ctr   \n",
      "4       2021-12-11                                     NW Austin Room   \n",
      "...            ...                                                ...   \n",
      "11369   2021-12-12                            Cheerful 4 bedroom vila   \n",
      "11370   2021-12-11  Upscale Riverside 2BR w/ W/D, Gym & Pool, near...   \n",
      "11371   2021-12-11      Clean, cozy place of your own | 1BR in Austin   \n",
      "11372   2021-12-11  Downtown Austin - 3BR Presidential - Rooftop Pool   \n",
      "11373   2021-12-11  Sonder at The Domain | Three-Bedroom Apartment...   \n",
      "\n",
      "                                             description  \\\n",
      "0      This upstairs apartment is surrounded by trees...   \n",
      "1      Zen East is situated in a vibrant & diverse mu...   \n",
      "2      Situated in a vibrant & diverse multicultural ...   \n",
      "3      Great central  location for walking to Convent...   \n",
      "4      <b>The space</b><br />Looking for a comfortabl...   \n",
      "...                                                  ...   \n",
      "11369  You'll have a great time at this comfortable p...   \n",
      "11370  Discover the best of Austin, with this two-bed...   \n",
      "11371  Stay for 90+ nights (minimum nights and rates ...   \n",
      "11372  3BR Presidential Suite in the newly built Wynd...   \n",
      "11373  At the intersection of commerce, culture, and ...   \n",
      "\n",
      "                                   neighborhood_overview  \\\n",
      "0      Hyde Park is close to downtown, UT, 6th street...   \n",
      "1                                                    NaN   \n",
      "2                                                    NaN   \n",
      "3      My neighborhood is ideally located if you want...   \n",
      "4      Quiet neighborhood with lots of trees and good...   \n",
      "...                                                  ...   \n",
      "11369                                                NaN   \n",
      "11370  This furnished apartment is in Riverside, acro...   \n",
      "11371                                                NaN   \n",
      "11372                                                NaN   \n",
      "11373  Quickly becoming known as Austin’s “new downto...   \n",
      "\n",
      "                                             picture_url    host_id  \\\n",
      "0      https://a0.muscache.com/pictures/52472f12-2e2e...    4635658   \n",
      "1      https://a0.muscache.com/pictures/4187/52d4f5d0...       2466   \n",
      "2      https://a0.muscache.com/pictures/5167505/b33b5...       2466   \n",
      "3      https://a0.muscache.com/pictures/14084884/b5a3...       8028   \n",
      "4      https://a0.muscache.com/pictures/23822033/ac94...       8186   \n",
      "...                                                  ...        ...   \n",
      "11369  https://a0.muscache.com/pictures/miso/Hosting-...  434801153   \n",
      "11370  https://a0.muscache.com/pictures/prohost-api/H...  107434423   \n",
      "11371  https://a0.muscache.com/pictures/a4re/floorpla...  359036978   \n",
      "11372  https://a0.muscache.com/pictures/74ad4e7c-c839...   26521212   \n",
      "11373  https://a0.muscache.com/pictures/prohost-api/H...  219500569   \n",
      "\n",
      "                                          host_url  ...  \\\n",
      "0        https://www.airbnb.com/users/show/4635658  ...   \n",
      "1           https://www.airbnb.com/users/show/2466  ...   \n",
      "2           https://www.airbnb.com/users/show/2466  ...   \n",
      "3           https://www.airbnb.com/users/show/8028  ...   \n",
      "4           https://www.airbnb.com/users/show/8186  ...   \n",
      "...                                            ...  ...   \n",
      "11369  https://www.airbnb.com/users/show/434801153  ...   \n",
      "11370  https://www.airbnb.com/users/show/107434423  ...   \n",
      "11371  https://www.airbnb.com/users/show/359036978  ...   \n",
      "11372   https://www.airbnb.com/users/show/26521212  ...   \n",
      "11373  https://www.airbnb.com/users/show/219500569  ...   \n",
      "\n",
      "      review_scores_communication review_scores_location review_scores_value  \\\n",
      "0                            4.91                   4.87                4.87   \n",
      "1                            4.83                   4.26                4.35   \n",
      "2                            4.40                   4.75                4.50   \n",
      "3                            4.80                   4.73                4.78   \n",
      "4                            4.94                   4.74                4.92   \n",
      "...                           ...                    ...                 ...   \n",
      "11369                         NaN                    NaN                 NaN   \n",
      "11370                         NaN                    NaN                 NaN   \n",
      "11371                         NaN                    NaN                 NaN   \n",
      "11372                         NaN                    NaN                 NaN   \n",
      "11373                         NaN                    NaN                 NaN   \n",
      "\n",
      "      license instant_bookable calculated_host_listings_count  \\\n",
      "0         NaN                t                              2   \n",
      "1         NaN                f                              3   \n",
      "2         NaN                f                              3   \n",
      "3         NaN                f                              1   \n",
      "4         NaN                f                              1   \n",
      "...       ...              ...                            ...   \n",
      "11369     NaN                t                              2   \n",
      "11370     NaN                t                             29   \n",
      "11371     NaN                t                            329   \n",
      "11372     NaN                f                              3   \n",
      "11373     NaN                t                             30   \n",
      "\n",
      "      calculated_host_listings_count_entire_homes  \\\n",
      "0                                               2   \n",
      "1                                               2   \n",
      "2                                               2   \n",
      "3                                               1   \n",
      "4                                               0   \n",
      "...                                           ...   \n",
      "11369                                           2   \n",
      "11370                                          29   \n",
      "11371                                         329   \n",
      "11372                                           3   \n",
      "11373                                          30   \n",
      "\n",
      "      calculated_host_listings_count_private_rooms  \\\n",
      "0                                                0   \n",
      "1                                                1   \n",
      "2                                                1   \n",
      "3                                                0   \n",
      "4                                                1   \n",
      "...                                            ...   \n",
      "11369                                            0   \n",
      "11370                                            0   \n",
      "11371                                            0   \n",
      "11372                                            0   \n",
      "11373                                            0   \n",
      "\n",
      "      calculated_host_listings_count_shared_rooms reviews_per_month  \n",
      "0                                               0              1.44  \n",
      "1                                               0              0.17  \n",
      "2                                               0              0.06  \n",
      "3                                               0              3.72  \n",
      "4                                               0              1.86  \n",
      "...                                           ...               ...  \n",
      "11369                                           0               NaN  \n",
      "11370                                           0               NaN  \n",
      "11371                                           0               NaN  \n",
      "11372                                           0               NaN  \n",
      "11373                                           0               NaN  \n",
      "\n",
      "[11374 rows x 74 columns]\n"
     ]
    }
   ],
   "source": [
    "#hyödyllisten kirjastojen tuominen\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "#datasetin lukeminen dataframeiksi\n",
    "URL= 'http://data.insideairbnb.com/united-states/tx/austin/2021-12-11/data/listings.csv.gz'\n",
    "Austin_listings = pd.read_csv(URL, compression = 'gzip')\n",
    "print (Austin_listings)\n",
    "df2 = pd.read_csv(URL)\n",
    "\n",
    "df2 = pd.read_csv(URL)\n",
    "#df2 on aiemminkin luotu dataframe Austinin listauksista\n",
    "#Valitaan datasta halutut sarakkeet tarkasteluun\n",
    "df2 = df2[['id','name','price','review_scores_location','review_scores_value','neighborhood_overview','reviews_per_month']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c77e0",
   "metadata": {},
   "source": [
    "Seuraavana pyrin harjoitustyössä siivoamaan dataa poistamalla sieltä tyhjiä arvoja sekä muutenkin saamaan sen selkeämpään muotoon tulevaa analysointi-vaihetta varten. Huomasin kuitenkin valinneeni varsinaiseen dataframeeni hieman liian kapesti dataa, joka mielestäni kostautui myöhemmissä vaihessa mallien ja kuvaajien sisältäessä mielestäni liian vähän datapisteitä. Itse laitoin tämän pitkälti oman kokemattomuuteni piikkiin, sillä en ole ennen toteuttanut vastaavanlaisia harjoituksia tai datan käsittelyjä. Datan siivoamisen toteuttamista alla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73dea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Muutettiin NaN-arvot nolliksi\n",
    "df2['review_scores_location'].fillna(0, inplace=True)\n",
    "df2['review_scores_value'].fillna(0, inplace=True)\n",
    "df2['neighborhood_overview'].fillna(0, inplace=True)\n",
    "df2['reviews_per_month'].fillna(0, inplace=True)\n",
    "#Tarkastetaan ettei tyhjiä arvoja enää ole \n",
    "#neighborhood_overviewin olisi mahdollisesti voinut vaihtaa tyhjäksi merkkijonoksi, mutta en ollut toteutuksesta aivan varma\n",
    "print(df2.isnull().sum())\n",
    "#Muutettiin hinta float-arvoksi ja poistettiin dollari merkit ja tuhaterottimet\n",
    "df2['price'] = df2['price'].str.replace('$','', regex = True)\n",
    "df2['price'] = df2['price'].str.replace(',','')\n",
    "df2['price'] = df2['price'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40714f67",
   "metadata": {},
   "source": [
    "Seuraavana vaiheena oli datan visualisointi sekä kuvaaminen. Loin siivoamani datan avulla lineaarisen regression, joka oli myös osa seuraavaa koneoppimisen osaa, scatter-kuvaajia sekä pylväsdiagrammeja. Tämä osa oli itselleni harjoitustyön mielenkiintoisin vaihe ja itsestäni oli hyvin mielekästä päästä näkemään, miten muokattu data käyttäytyi, kun sen avulla luotiin erilaisia kuvaajia. Harjoituksessa toteuttamani datan käsittelyt sekä kuvaajien muodostamiset ovat nähtävillä samalla GitHub sivullani, jolla myös tämä oppimispäiväkirja sijaitsee. Mielestäni ei ole mielekästä tuoda kaikkia harjoitustyössä jo aiemmin tekemiäni Pythonin pätkiä osaksi myös oppimispäiväkirjaani, joten nuo ovat omana kokonaisuutenaan nähtävissä niin harjoitustyössäni kuin pelkkänä datan käsittelynä Jupyter notebookkina. \n",
    "\n",
    "Viimeisimmät vaiheet harjoitustyön toteutuksessa olivat koneoppimisen käsittely sekä työn kokonaisuuden arviointi. Koneoppimisen kohdassa muodostin lineaarisen regression mielestäni järkevien datapistejoukkojen välille ja tarkastelin minkälaista yhteyttä tekijöiden välillä voitiin havaita kuvaajien avulla. Ennen tätä tarkastelin myös eri datapisteiden välisiä korrelaatioita, joiden avulla päätin, mitä joukkoja tarkastelisin lineaarisen regressioni vaiheessa. Mielestäni koneoppimisen vaihe oli mielenkiintoinen, mutta erityisesti tässä huomasin aiemmin mainitsemani datan siivoamisen kokemattomuuden kostautuneen datan määrän mielestäni vääristäessä saamiani regressio- sekä korrelaatio tuloksia. Kuitenkin tämän kohdan toteuttaminen oli kaikenkaikkiaan itselleni hyvin opettavaista. Kokonaisuuden arvioinnin kohdassa, jossa myös keskityttiin dataprojektin toimeenpanoon sekä saatuihin tuloksiin ja niiden arvioimiseen, itselläni oli vaikeuksia muodostaa tarkastelemani analyysin pohjalta järkeviä johtopäätöksiä. En ollut lähtenyt tarkastelmaan valittua dataa riittävän fokusoituneesti etsien ratkaisuja tiettyihin kysymyksiin. Jo tarkastelun alussa minun olisi tullut määritellä selkeästi minkä aiheiden välisiä vaikutuksia olisin lähtenyt tutkimaan ja myös valita dataframeni tämän mukaisesti. Tämän avulla olisin voinut varmasti saada paljon selkeämpiä ja helpommin havaittavia yhteyksiä jalostamastani datasta. Tämä on hyvä pitää mielessä tulevaisuudessa mahdollisten dataprojektien kohdalla. Harjoitustyö oli mielestäni hvin käytännöllinen tapa opetella kurssin aihepiirin asioita käytännössä, mutta riittävän yksinkertaisesti. \n",
    "\n",
    "Tärkeimpiä oppejani tältä viikolta sekä yleisesti harjoitustyöstä olivat käytännössä kaikki siinä käytettävät Python-komennot sekä kirjastojen importaukset, jotka ovatkin samalla tämän kappaleen demokoodi. Muita tärkeitä oppeja olivat data-analyysin eri vaiheiden oppiminen. En ollut ajatellut, miten monta eri vaihetta varsinaista analyysiä edeltää, joten sen oppiminen oli itselleni mielekästä. Lisäksi huomasin, miten tärkeää analyysia tehdessä on valita lähtödata huolellisesti, jotta sen tarjoamasta informaatiosta saada selkeitä tuloksia, ja jotta tulosten laatu olisi vaaditulla tasolla. Tässä itselläni oli ainakin kehitettävää harjoitustyöhöni peilaten. Tämä olisi myös oma kehittämisehdotukseni, että valittujen datapisteiden merkitystä korostettaisiin vieläkin enemmän ennen harjoituksen aloitusta. Näin mahdollisesti tehtiinkin, mutta itselleni tämä ei ollut tullut riittävästi esille vaikka kaikki luennot olinkin tähän mennessä ja tämän jälkeenkin katsonut. On kuitenkin hyvin mahdollista, että tämä informaatio on mennyt vain itseltäni ohitse. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28f5646",
   "metadata": {},
   "source": [
    "## Viides viikko, Vierailuluento Futurice\n",
    "Itse olin ikävästi töissä viidennen viikon luennon aikana, joten katsoin tallenteena viimevuotisen vierailuluennon. Luennon aiheena oli NPL, jossa tarkasteltiin tavallista luonnollista kieltä datalähteenä. Esimerkkehjä tästä ovat esimerkiksi chattibotit, automaattikääntäjät sekä isompien tekstimassojen analysointi. Yleensä NPL linkittyy johonkin toiseen data- tai koneoppimisratkaisuun ja toimiin sen kanssa yhteistyössä. Esimerkkinä esiteltiin tekstimuotoisen datan käsittelyä, jossa hukkasanalistan avulla pyrittiin siistimään tekstimuotoisesta datasta turhia sanoja, jotka eivät ole datan laadun kannalta merkittäviä. Tämän \"turhan datan\" poistamalla vähennetään analytiikkaan kuluvia resursseja ja saadaan selkeämpää dataa analytiikan hyödynnettäväksi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c073c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Luennolla annattu esimerkki hukkasanalistan käsittelystä sekä tarvittavien kirjastojen importaus\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import libvoikko #perusmutoistamiseen käytetty kirjasto\n",
    "import fasttext as ft #Mallin opetuskseen käytettävä kirjasto\n",
    "#import nltk #Natural Language Toolkit, hyödyllisiä NLP-perustyökaluja\n",
    "import re #Regex\n",
    "\"Paketit importattu\"\n",
    "\n",
    "v = libvoikko.Voikko(u\"fi\")\n",
    "\n",
    "with open('stopwords.txt', 'r', encoding='utf8') as sw:\n",
    "    stopwords = sw.readlines()\n",
    "    sw.close()\n",
    "\n",
    "stopwords = [i.split(\"\\n\")[0] for i in stopwords]\n",
    "#Lähde: Vierailuluento Futurice; https://github.com/MikkonenTS/Futurice-Joda/blob/main/FuturiceJODA.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f52fa28",
   "metadata": {},
   "source": [
    "Edellä esitelty demokoodi on Futuricen Jupyter Notebookista, jossa esiteltiin hukkasanalistan käsittelyä. Hukkasanoilla takoitetaan sanoja, jotka eivät tuo informaatiota tekstiin. Tälläisiä sanoja ovat esimerkiksi prepositiot tai erisnimet. Nämä poistamalla saadaan teksti paljon informatiivisemmaksi muokatessa se datamuotoiseksi. Tämä oli itselleni täysin uusi asia, enkä ollut ennen ajatellut sen enempää, miten chattibotit tai muut NPL-pohjaiset datankäsittelymenetelmät toimivat. Oli mielenkiintoista ymmärtää, miten sanalistoja tekemällä sekä ylimääräisiä sanoja suodattamalla voidaan luoda tekstistä dataa ja parantaa tekstin informaatioarvoa.\n",
    "\n",
    "Seuraavana aiheena luennonmateriaalissa oli esikäsittely, jota hyödynnetään erityisesti koneoppimisenprosesseissa. Esikäsittelyn tavoitteena on parantaa koneoppimisessa käytettävän opetusdatan laatua sekä vähentää kohinaa, jota esimerkiksi NPL-menetelmässä ovat hukkasanat, joita edellä käsiteltiin. Kohina vaikeuttaa hyödyllisen datan piirteiden erottelua. Tämän jälkeen koneoppimisessa seuraa varsinaisen mallin opetus, jossa muodostetaan sanavektoreita, jotka ovat riippuvaisia sanojen kontekstista. Mallin opetuksen jälkeen mallia ja sen toimivuutta testataan. Luennolla esiteltiin pohdinta: miksi tulee testata muutakin kuin vain montako ennustetta luotu malli sai oikein ja montako meni väärin? Itse näkisin tämän liittyvän aiemmin mainittuun kohtaa, jossa todettiin mallin muodostuksessa pyrittävän luomaan sanavektoreita, jotka muodostuvat sanojen kontekstin perusteella. Suoraa oikeiden ja väärien vastausten perusteella ei välttämättä pystytä ottamaan kantaa mahdollisiin konteksteihin, joita mallille ei ole opetettu. Osa vääristä vastauksista voi olla todelisuudessa oikeita, mutta kontekstissa, jota malli ei ymmärrä. Mallin testauksen jälkeen malli pyritään soveltamaan uudella datalähteellä ja tutkitaan tämän avulla mallin soveltuvuutta erilaisiin käyttökohteisiin. Luennolla esimerkkinä soveltamisesta käytettiin ministerien twiittejä, joista poistettiin hukkasanoja ja muodostettiin dataa twiittien sisällöstä.\n",
    "\n",
    "Sillä itse katsoin viimevuoden luennon tallenteen, voi materiaalissa olla joitakin eroja tämän vuoden Jupyter Notebookkiin, jota tämän vuoden luennolla käytettiin. Kuten jo aiemmalla, koneoppimista käsitelleen luennon pohdinnassa mainitsin, on koneoppiminen mielestäni samaan aikaan erittäin mielenkiintoinen aihe, mutta samalla kaikkein hankalimmin itselleni ymmärrettävissä. Tästä syystä luentoa oli mielenkiintoista kuunnella, siellä esiteltyjen käytännön käyttökohteiden laajentamisen aiemmista itseajavista autoista chatbottien sekä automaattikääntäjien toimintaan. En ollut ajatellut miten paljon dataa on mahdollista kerätä \"normaalista\" tekstistä tai miten tätä tekstiä tulisi muotoilla ja siivota, jotta siitä saadaan tuotua datan kannalta merkittävä informaatio selkeämmin esille. \n",
    "\n",
    "Luennon tärkeimpiä oppeja itselleni olivat mielestäni koneoppimisen sovelluskohteiden ymmärtäminen, koneoppimisen mallien luomisen prosessi sekä mitä tulee tehdä, jotta oppimisen mallista saadaan mahdollisimman tarkka sekä miten mallia, ja sen toimintaa voidaan testata. Lisäksi mielestäni oli tärkeää mihin sanoista dataa muodostavat koneoppimisen mallit toimivat käytännössä sanavektoreita muodostettaessa sekä miten tätä normaalista kielestä koostuvaa dataa pyritään siivoamaan hukkasanojen poistamisella. Viikon luento oli lähes kokonaan itselleni uutta, joten oppineeni suhteellisen paljon aiheesta, vaikken sitä vielä käytännössä osaisikaan hyödyntää. Opin myös hieman erilaisen kirjastojen asennustavan kuin pelkkien pandas kirjastojen importaamisen, tai ainakaan itselleni ei ollut tullut vastaan aiemmin aivan luennon alussa esiteltyä pakettidatan sekä kirjastojen asennusta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8184d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Haetaan pakettidata ja hukkasanalista avoimesta AWS S3-bucketista\n",
    "!aws s3 --no-sign-request cp s3://nlpluentomateriaalit/requirements.txt requirements.txt\n",
    "!aws s3 --no-sign-request cp s3://nlpluentomateriaalit/stopwords.txt stopwords.txt\n",
    "#Asennetaan tarvittavat kirjastot haetun requirements-tiedoston perusteella\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "#Asennetaan voikko-kirjasto suoraan versionhallinnasta\n",
    "!sudo apt -y install -y voikko-fi python-libvoikko\n",
    "#Lähde: Vierailuluento Futurice; https://github.com/MikkonenTS/Futurice-Joda/blob/main/FuturiceJODA.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88054e33",
   "metadata": {},
   "source": [
    "## Kuudes viikko, Ohjaamaton koneoppiminen\n",
    "Kuudennella viikolla jatkettiin keskittymistä koneoppimiseen, mutta tällä kertaa hieman aiemmasta poikkeavalla näkökulmalla. En itse ollut paikalla tällä luennolla, vaan katsoin sen jälkikäteen tallenteena. Luennolla käsiteltiin ohjaamatonta oppimista, miten sitä sovelletaan sekä miten sen avulla voidaan tukea päätöksentekoa analytiikassa. Pohjimmiltaan ohjaamattomalla oppimisella pyritään mallintamaan vähemmän suoraviivaisia koneoppimisen menetelmiä verrattuna ohjattuun oppimiseen, jossa usein tarkastellaan tietyn asian 1 vaikutusta suorasti asian 2 toimintaan. Tämä ei kuitenkaan aina ole mahdollista, vaan joskus analyysin kohteet ovat monimutkaisempia eikä niitä ole mahdollista mallintaa näin suoraviivaisesti. Ohjaamattoman oppimisen menetelmistä luennolla esiteltiin ostokorianalyysi, ryvästäminen sekä aihemallinnus. Lisäksi mainittiin verkostoanalyysi, joka ei kuitenkaan varsinaisesti ole ohjaamatonta oppimista, sillä verkostosta ei voi itsellään oppia, vaan kuten Marvel esimerkillä avattiin, tulee yksittäisen tekijän suhde tietää muihin pisteisiin. Aina tämäkään ei kuitenkaan tuo varsinaista oppimista. Näistä malleista yksityiskohtaisemmin tarkasteltiin luennolla ryvästämistä sekä aihemallinnusta. Näistä ostoskorimallia avattiin lähinnä suullisesti luennon aluksi esittämällä esimerkin, miten kaupassa voidaan tarkastelemalla asiakkaiden satunnaisia ostoskoreja pyrkiä selvittämään näiden ostosten perusteella, mikä voisi olla järkevä tuotelayout tukemaan eri tuotteiden valintaa. Varsinainen materiaalin tarkastelu aloitettiin ryvästämisestä, jonka toiminta perustuu menetelmään, jossa datan pisteet jaetaan erillisiin ryppäisiin, jotka sijaitsevat mahdollisimman pienellä alueella. Ryppäät tulee kuitenkin pyrkiä saamaan sijoitettua mahdollisimman kauas toisistaan.\n",
    "\n",
    "Tälläisen toimintamallin käyttökohteena annettiin esimerkki tilanteesta, jossa käytössä oleva tietojoukko koostuuu tapauksista, joilla on useampia ominaisuuksia, jotka ovat kuitenkin jaettu muiden tapausten kanssa. Tätä lukiessani jälkikäteen itselläni oli hieman vaikeuksia sisäistää, mitä tämä toddellisuudessa tarkoittaa ja jouduin katsomaan luennon tallennetta uudelleen, enkä vielä tämänkään jälkeen ollut aivan varma olinko ymmärtänyt toiminnan oikein. Tämä oli mielestäni hieman turhauttavaa, mutta kuten jo aiemmin mainitsin, on koneoppiminen kokonaisuutena mielestäni samalla mielenkiintoisin, mutta myös haastavin kurssin aihealue. Mainitut tietojoukot ryvästämisessä kuitenkaan ei ole yleensä tietoa, mihin tiettyyn joukkoon tai luokkaan tietty syyte kuuluu. Tämä tietojoukkojen jakaminen on ryvästämisessä annettu tietylle algoritmille, joka oppimisdatan pohjalta oppii ennustamaan, mihin luokkaan mikäkin tietojoukko kuuluu. Ohjaamattomassa ryvästämissä pyritään siis löytämään aineistoista samallaisia havaintoja. Tämä voidaan toteuttaa esimerkiksi materiaalissa mainitun K-Means-algoritmien avulla, joka pyrkii etsimään tietylle pistejoukkojen klustereille keskipisteitä juuri pistejoukkoja ryhmittelemällä. Klustereiden määrittely puolestaan perustuu aiempii keskipisteisiin. Luennolla esiteltiin erilaisten ryvästämiseen liittyvien kirjastojen importaamista, joka oli itselleni uutta datatieteen saralla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c9b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "# from src import mglearn\n",
    "hv.extension('bokeh')\n",
    "%matplotlib inline\n",
    "#Varsinainen kirjastojen importaaminen oli itselleni tuttua mutta suurin osa näistä luennon kirjastoista olivat minulle\n",
    "#tuntemattomia\n",
    "#Lahde: Jupyter notebook luento 6: https://github.com/InfoTUNI/joda2022/blob/master/luentomuistio/luento06.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b467d6e2",
   "metadata": {},
   "source": [
    "Ryvästämistä demottiin myös käytännössä tarkastelemalla valmista elokuva-aineistoa. Datasta siivottiin tyhjiä arvoja ja tarkasteltiin puuttuuko yksittäisistä soluista arvoja, jotka olisi mahdollista täydentää. Datan tarkastelemista jatkettiin vielä luomalla kuvaajia, josta pyrittiin huomaamaan erityispiirteitä, joita aineistoista olisi hyvä huomata.\n",
    "\n",
    "Itselleni datan käsittelyn seuraaminen oli mielenkiintoista ja erityisesti mallinnus KMeansin toiminnasta oli hyvin havainnollistava. Tämä oli erittäin positiivista, sillä aihe oli yleisesti mielestäni hieman epäselvää ja siitä konkreettisemman kuvan saamisessa mallinnus auttoi jonkin verran. Klustereiden määrän valinnan avaaminen auttoi myös ymmärtämään hieman, miten keskipisteiden määrittäminen ryvästämisessä toimii. Klustereiden määrää havainnollistettiin luennon materiaalissa määrittämällä testiajo arvioidulla klusterimäärällä ja peilaamalla tulosten merkittävyyttä ja klustereiden määrää keskenään:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fee936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Klustereiden määrää testattiin luennon materiaalissa alla olevan koodin avulla\n",
    "#Tiedän ettei copypastan käyttäminen demokoodina ole paras mahdollinen menetelmä, mutta\n",
    "#aiheen ollessa hyvin tuntematon itselleni en usko osaavani tuottaa vielä omaa koodia aiheesta\n",
    "\n",
    "# Valitaan laskettavien klustereiden määrä. Mikä olisi järkevä klustereiden määrä maksimissaan.\n",
    "# Onko 20 liikaa?\n",
    "c = range(1, 20)\n",
    "# Sovitetaan for-silmukassa KMeans kaikille c:n arvoille\n",
    "kmeans = [KMeans(n_clusters=i) for i in c]\n",
    "score = [kmeans[i].fit(dfNumNorm).score(dfNumNorm) for i in range(len(kmeans))]\n",
    "#Tulosten perusteella päätettiin valita kolme klusteria sillä vaikutti siltä ettei useamman valinnalla\n",
    "#ollut suurta hyötyä \n",
    "#Lähde: Jupyter työkirja luento 6: https://github.com/InfoTUNI/joda2022/blob/master/luentomuistio/luento06.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4788ec0",
   "metadata": {},
   "source": [
    "Seuraava aihe oli aihemallinnus, jossa tarkastellaan dokumenttien kokoelmassa esiintyviä abstrakteja aiheita. Näiden avulla pyritään löytämään piilotettuja semanttisia rakenteita. Luennon aiheista itselleni, haasteistaan huolimatta, ryvästäminen oli kuitenkin selkeämmin ymmärrettävä kuin aihemallinnus. Luennon esimerkit aiheesta olivat hyvin mielenkiintoisia sekä kuvaavia, tarkasteltaessa myös tässä elokava-arvioita sekä niistä mahdollisesti saatavaa informaatiota. Tarkastelussa huomattiin kuitenkin luokittelun toimivuuden olevan hieman kyseenalainen tai monitulkintainen, ja aiheesta korostettiinkin, miten mahdollisesti \"huonon\" lähtödatan perusteella hyvinkin tehty mallinnus ei tuo lisää informaatiota, mikäli sellaista ei ole datassa alunperinkää kunnolla saatavilla. Luennolla tätä ilmiötä kuvattiin \"garbage in-garbage out\" fraasilla.\n",
    "\n",
    "Luento oli mielestäni aiheeltaan hyvinkin mielenkiintoinen, vaikka se keskittyikin hieman subjektiivisemman datan tarkasteluun, josta ei välttämättä saada \"oikeanlaisia\" vastauksia haluttuihin kysymyksiin analytiikan avulla. Itselleni keskisimpiä oppeja luennolta olivat käsitteen ohjaamaton koneoppiminen sisäistäminen, sillä en ollut siitä aiemmin kuullutkaan, erilaisten tapahtumien yhteisen esiintyvyyden avulla luotujen oppimisen mallien hyväksi käyttäminen, kuten ostoskorimallin esimerkissä, sekä lisää hieman epätavallisemman datan mallintamisesta verrattuna vain arkisiin numeroihin tai totuusarvoihin. Aihe kuitenkin avasi myös yhä lisää itselleni, miten paljon itselläni on vielä opittavaa datatieteissä, joidenkin perusasioidenkin ollessa hieman lapsenkengissä. Tämän voi toisaalta mielestäni nähdä myös positiivisena, aina kun on mukavaa oppia uutta, jota voi vielä mahdollisesti hyödyntää myöhemmin tosielämässä. Kehittämisehdotuksia tälle aiheelle ei itselläni oikeastaan ole. Käsitellyt aiheet käytiin mielestäni hyvin läpi, vaikka itselleni aiheen käytäntö olikin välillä haastava ymmärtää."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cc72b9",
   "metadata": {},
   "source": [
    "## Seitsemäs viikko, Visuaalinen analytiikka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bbe95b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
